---
title: "Tarea: Árboles y bosques aleatorios"
output: html_notebook
---

```{r, eval=FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(ranger)
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
```

Cosideramos los datos de la tarea 6:

```{r, message=FALSE, warning = FALSE}
docs_tbl <- read_csv("../datos/sentiment/matriz_tarea_6.csv")
polaridad <- read_csv("../datos/sentiment/polaridad_tarea_6.csv")
names(docs_tbl) <- paste0("w", names(docs_tbl)) %>% 
    make.names
docs_tbl <- mutate(docs_tbl, polaridad = pull(polaridad))
set.seed(9921)
entrena_tbl <- sample_frac(docs_tbl, 0.75)
val_tbl <- anti_join(docs_tbl, entrena_tbl)
```


## Árboles

Construimos primero un árbol podado:

```{r, fig.width = 10, fig.height = 8}
arbol_grande <- rpart(polaridad ~ ., method = "class",
      data = entrena_tbl, cp = 0)
arbol_podado <- prune(arbol_grande, cp = 0.011)
prp(arbol_podado, type = 4, extra = 104, digits=2,  compress = FALSE, cex = 1.2)
```


**Preguntas**

1. ¿Qué significa la información que hay en cada nodo? Examina el primer nodo y cómo
divide la muestra. ¿Cuáles son los nodos donde el árbol clasifica en reseña negativa?

2. Evalúa la tasa de clasificación correcta de  entrenamiento y prueba para este árbol. Repite para el árbol completo. ¿Cómo detectas que hay sobreajuste en el árbol no podado?

3. Poda el árbol para mostrar solamente un árbol con unos 5-7 nodos terminales. ¿Qué variables son usadas?  ¿Cuál es el error de entrenamiento y prueba?

## Bosque aleatorio

Ajustamos un bosque con parámetros cercanos al default (mtry = sqrt(num_variables),
min.node.size = 10):

```{r}
bosque_docs <- ranger(polaridad ~ ., data = entrena_tbl,
       mtry = 50, min.node.size = 5, num.trees = 500,
       importance = "permutation",
       probability = TRUE)
bosque_docs
```

1. ¿Qué significa la salida OOB prediction en la salida de arriba? ¿Con qué muestra se calcula esta medida de  error?

2. Calcula la matriz de confusión de prueba para el bosque. Calcula precisión y recall para cada una de las clases. Compara el error de clasificación con los árboles de la parte anterior.

3. Afina los parámetros para obtener mejor desempeño, usando el error OOB. Puedes
usar el siguiente código para hacer una búsqueda aleatoria. Considerando
esta corrida, adapta el grid para encontrar un mejor error:

```{r}
# función que ajusta un bosque y devuelve error
ajusta_bosque <- function(mtry, min.node.size, num.trees, ...){
    ajuste <- ranger(polaridad ~ ., data = entrena_tbl,
       mtry = mtry, min.node.size = min.node.size,
       num.trees = num.trees, probability = TRUE)
    # reportar error oob, puedes calcular otras cosas aquí
    ajuste$prediction.error
}
grid_params <- list(mtry = seq(1, 300, 2), min.node.size = seq(1, 50, 5), 
                    num.trees = 500) %>% cross_df()
random_params <- grid_params %>% sample_n(20)
resultados_oob <- random_params %>% 
    mutate(error = pmap_dbl(random_params,  ajusta_bosque))
resultados_oob
ggplot(resultados_oob, aes(x = mtry, y = error, colour = min.node.size)) +
    geom_point()
```


## Importancia de variables

En las notas puedes ver cómo se define la importancia de variables usando el método de permutaciones. Esta importancia está dada en términos de caída del error de predicción out-of-bag (en este caso el score de Brier) 
cuando cada variable se permuta al azar y se hacen las predicciones con
la variable permutada.

**Pregunta**: 

1. ¿por qué no es posible "quitar" la variable una vez que hemos construido el bosque?

```{r}
imp_tbl <- tibble(importancia = bosque_docs$variable.importance, 
       variable = names(bosque_docs$variable.importance)) %>% 
    mutate(variable = fct_reorder(variable, importancia))
# 20 más importantes
imp_tbl_top <- imp_tbl %>% top_n(20, importancia)
ggplot(imp_tbl_top, aes(x = variable, y = importancia)) +
    coord_flip() + geom_point()
```


**Pregunta**: examina las primeras 40 variables en importancia. ¿Qué palabras positivas y negativas aparecen?