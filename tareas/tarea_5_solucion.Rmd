---
title: "Tarea: clasificación multinomial en keras"
output: html_notebook
---

## Preparación de datos

```{r, message = FALSE}
library(tidyverse)
library(keras)
use_session_with_seed(421) # ayuda a reproducibilidad, pero más lento
set.seed(112)
zip_train <- read_csv("../datos/zip-train.csv") 
zip_test <- read_csv("../datos/zip-test.csv")
zip_train_x <- zip_train %>% select(-X1) %>% as.matrix
zip_test_x <- zip_test %>% select(-V1) %>% as.matrix
zip_train_y <- zip_train$X1
zip_test_y <- zip_test$V1
```

```{r}
# Convertir a categóricas
num_clases <- 10
y_train <- to_categorical(zip_train_y, num_clases)
y_test <- to_categorical(zip_test_y, num_clases)
```

## Definir modelo

Definimos regresión logística multinomial
```{r}
model <- keras_model_sequential() %>%
  layer_dense(units = num_clases, activation = "softmax")
```

Compilamos y corremos:

```{r}
model %>% compile(
  loss = loss_categorical_crossentropy,
  optimizer = optimizer_sgd(lr = 0.2),
  metrics = c('accuracy') # ver tasa de correctos
)
# Entrenar con descenso en gradiente
history <- model %>% fit(
  zip_train_x, y_train,
  batch_size = nrow(zip_train_x),
  validation_split = 0.5,
  verbose = 0,
  epochs = 500)

```


Evalúa con la muestra de prueba (recuerda que entropía cruzada
es lo mismo que devianza promedio, pero sin el factor de 2):

```{r}
scores <- model %>% evaluate(
  zip_test_x, y_test, verbose = 0
)

# Output metrics
cat('Prueba - pérdida (entropía cruzada):', scores[[1]], '\n')
cat('Prueba - tasa de correctos :', scores[[2]], '\n')

```

## Coeficientes del modelo


```{r}
coeficientes <- get_weights(model)[[1]]
ordenadas <- get_weights(model)[[2]]
```



**Pregunta 1** ¿De qué tamaño es la matriz de coeficientes? Explica la dimensión
en términos de los datos (entradas y variable a predecir)

Coeficientes es de 256 x 10 (pixeles x clases), más 10 ordenadas (una para cada clase)

**Pregunta 2** Grafica los coeficientes asociados al dígito 1. ¿Cuáles son los
dígitos que tienen valores positivos grandes (aumentan la probabilidad de
que el dígito sea 1)?

Por ejemplo, para graficar un dígito, hacemos:

```{r}
graficar_vector <- function(x){
    mat <- matrix(as.numeric(x), nrow = 16)[1:16, 16:1] 
    image(mat)
}
graficar_vector(zip_train_x[1, ])
graficar_vector(coefs_0 <- coeficientes[, 1])
coefs_0_mod <- coefs_0
coefs_0_mod[coefs_0 < 0] <- 0
graficar_vector(coefs_0_mod)
```

Aplica la misma función para coeficientes

## Predicciones

Puedes producir predicciones probabilísticas con Keras de la siguiente forma. 
Para los casos 1 y 30 de prueba, por ejemplo:

```{r}
probas <- predict(model, x = zip_test_x[c(1,30), ,drop = FALSE]) %>% t
probas %>% round(3)
```

*Pregunta 3* reconstruye estas probabilidades usando la matriz de coeficientes
y ordenadas (interceptos) en el paso anterior. Tip: multiplica coeficientes por los datos de entrada, suma las ordenadas y aplica la función softmax (aplica exponencial y normaliza):

```{r}
preds_lineal <- (t(coeficientes) %*% t(zip_test_x[c(1,30), ,drop = FALSE])) + as.numeric(ordenadas)
softmax <- function(x){  exp(x) / sum(exp(x))  }
softmax <- function(x){  exp(x - max(x)) / sum(exp(x - max(x)))  }
apply(preds_lineal, 2, softmax) %>% round(3)
```


## ¿Qué pasa si corremos más iteraciones?


Ahora corremos más iteraciones:


```{r}
model %>% fit(
  zip_train_x, y_train,
  batch_size = nrow(zip_train_x),
  epochs = 6000,
  validation_split = 0.5,
  verbose = 0
)
scores <- model %>% evaluate(
  zip_test_x, y_test
)

# Output metrics
cat('Prueba - pérdida (entropía cruzada):', scores[[1]], '\n')
cat('Prueba - tasa de correctos :', scores[[2]], '\n')
```

**Pregunta 4**: ¿Qué modelo ajustado es mejor? Explica por qué. El modelo con menos iteraciones tiene menor error de validación (devianza o entropía cruzada). La razón es que con más iteraciones el modelo sobreajusta los datos.